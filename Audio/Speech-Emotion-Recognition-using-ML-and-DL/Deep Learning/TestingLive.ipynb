{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "colab_type": "code",
        "id": "Yu6WYdNRRvJ_",
        "outputId": "b58d94b2-44f0-4d17-aa8f-56e67eff35d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_1 (Conv1D)           (None, 40, 64)            384       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 40, 64)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 40, 64)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPoolin  (None, 10, 64)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 10, 128)           41088     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 10, 128)           0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 10, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPoolin  (None, 2, 128)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 2, 256)            164096    \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 2, 256)            0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 2, 256)            0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 4104      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 209672 (819.03 KB)\n",
            "Trainable params: 209672 (819.03 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Recording...Press the 'ESC' key to stop.\n",
            "Stopped recording.\n",
            "1/1 [==============================] - 0s 330ms/step\n",
            "Prediction is   sad\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This file can be used to try a live prediction. \n",
        "\"\"\"\n",
        "\n",
        "import keras\n",
        "import numpy as np\n",
        "import librosa\n",
        "import pyaudio\n",
        "import wave\n",
        "import keyboard\n",
        "\n",
        "class livePredictions:\n",
        "    \"\"\"\n",
        "    Main class of the application.\n",
        "    \"\"\"\n",
        "\n",
        "    # def __init__(self, path, file):\n",
        "    def __init__(self, path):\n",
        "        \"\"\"\n",
        "        Init method is used to initialize the main parameters.\n",
        "        \"\"\"\n",
        "        self.path = path\n",
        "        # self.file = file\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"\n",
        "        Method to load the chosen model.\n",
        "        :param path: path to your h5 model.\n",
        "        :return: summary of the model with the .summary() function.\n",
        "        \"\"\"\n",
        "        self.loaded_model = keras.models.load_model(self.path)\n",
        "        return self.loaded_model.summary()\n",
        "    \n",
        "    def record_audio(self, duration=5, filename='recorded_audio.wav'):\n",
        "        \"\"\"\n",
        "        Method to record audio from the microphone.\n",
        "        :param duration: duration of the recording in seconds.\n",
        "        :param filename: name of the recorded audio file.\n",
        "        \"\"\"\n",
        "        audio = pyaudio.PyAudio()\n",
        "\n",
        "        # Set the audio parameters\n",
        "        format = pyaudio.paInt16\n",
        "        channels = 1\n",
        "        rate = 44100\n",
        "        frames_per_buffer = 1024\n",
        "\n",
        "        # Create an audio stream\n",
        "        stream = audio.open(format=format, channels=channels,\n",
        "                            rate=rate, input=True,\n",
        "                            frames_per_buffer=frames_per_buffer)\n",
        "\n",
        "        print(\"Recording...Press the 'ESC' key to stop.\")\n",
        "        frames = []\n",
        "\n",
        "        # for _ in range(0, int(rate / frames_per_buffer * duration)):\n",
        "        #     data = stream.read(frames_per_buffer)\n",
        "        #     frames.append(data)\n",
        "\n",
        "        # print(\"Finished recording.\")\n",
        "\n",
        "        # # Stop and close the audio stream\n",
        "        # stream.stop_stream()\n",
        "        # stream.close()\n",
        "        # audio.terminate()\n",
        "\n",
        "        # # Save the recorded audio to a WAV file\n",
        "        # with wave.open(filename, 'wb') as wf:\n",
        "        #     wf.setnchannels(channels)\n",
        "        #     wf.setsampwidth(audio.get_sample_size(format))\n",
        "        #     wf.setframerate(rate)\n",
        "        #     wf.writeframes(b''.join(frames))\n",
        "\n",
        "        # return filename\n",
        "        \n",
        "        while True:\n",
        "            data = stream.read(frames_per_buffer)\n",
        "            frames.append(data)\n",
        "            \n",
        "            # Check if the 'ESC' key is pressed to stop recording\n",
        "            if keyboard.is_pressed('esc'):\n",
        "                print(\"Stopped recording.\")\n",
        "                break\n",
        "\n",
        "        # Stop and close the audio stream\n",
        "        stream.stop_stream()\n",
        "        stream.close()\n",
        "        audio.terminate()\n",
        "\n",
        "        # Save the recorded audio to a WAV file\n",
        "        with wave.open(filename, 'wb') as wf:\n",
        "            wf.setnchannels(channels)\n",
        "            wf.setsampwidth(audio.get_sample_size(format))\n",
        "            wf.setframerate(rate)\n",
        "            wf.writeframes(b''.join(frames))\n",
        "\n",
        "        return filename\n",
        "\n",
        "    def makepredictions(self, audio_file):\n",
        "        \"\"\"\n",
        "        Method to process the files and create your features.\n",
        "        \"\"\"\n",
        "        data, sampling_rate = librosa.load(audio_file)\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
        "        x = np.expand_dims(mfccs, axis=1)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        predictions = self.loaded_model.predict(x)\n",
        "        predicted_class_index = np.argmax(predictions)\n",
        "        print(\"Prediction is\", \" \", self.convertclasstoemotion(predicted_class_index))\n",
        "\n",
        "    @staticmethod\n",
        "    def convertclasstoemotion(pred):\n",
        "        \"\"\"\n",
        "        Method to convert the predictions (int) into human readable strings.\n",
        "        \"\"\"\n",
        "        \n",
        "        label_conversion = {'0': 'neutral',\n",
        "                            '1': 'calm',\n",
        "                            '2': 'happy',\n",
        "                            '3': 'sad',\n",
        "                            '4': 'frustration',\n",
        "                            '5': 'fearful',\n",
        "                            '6': 'disgust',\n",
        "                            '7': 'surprised'}\n",
        "\n",
        "        for key, value in label_conversion.items():\n",
        "            if int(key) == pred:\n",
        "                label = value\n",
        "        return label\n",
        "        # return label_conversion.get(pred,'Unknown')\n",
        "\n",
        "# Here you can replace path and file with the path of your model and of the file \n",
        "#from the RAVDESS dataset you want to use for the prediction,\n",
        "# Below, I have used a neutral file: the prediction made is neutral.\n",
        "\n",
        "pred = livePredictions(path='SER_model.h5')\n",
        "# pred = livePredictions(path='SER_model.h5',file=r'C:\\Users\\a21ma\\OneDrive\\Desktop\\HackX\\Audio\\Speech-Emotion-Recognition-using-ML-and-DL\\examples\\10-16-07-29-82-30-63.wav')\n",
        "\n",
        "pred.load_model()\n",
        "audio_file = pred.record_audio(duration=5, filename='recorded_audio.wav')\n",
        "pred.makepredictions(audio_file)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TestingLive.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
